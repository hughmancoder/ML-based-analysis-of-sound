{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc4d04fb",
   "metadata": {},
   "source": [
    "# IRMAS Test Evaluation\n",
    "\n",
    "Load the trained `CNNVarTime` checkpoint, run it on the precomputed IRMAS test mel windows, aggregate predictions back to the clip level, and report clip-level accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cb4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Fixed IRMAS test evaluation (single-class model, clip-level) --------\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.models import CNNVarTime\n",
    "from src.utils.datasets import IRMASTestWindowDataset\n",
    "from src.utils.utils import IRMAS_CLASSES  # only for label names if ckpt lacks map\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "IRMAS_TEST_MANIFEST = \"data/manifests/irmas_test_mels.csv\"   # <-- set yours\n",
    "RESUME_CKPT         = \"saved_weights/irmas_pretrain_single_class/train_2/best_epoch_0075_val_acc_66.50.pt\"\n",
    "BATCH_SIZE          = 64\n",
    "NUM_WORKERS         = 2\n",
    "PROJECT_ROOT        = Path.cwd()\n",
    "\n",
    "DEVICE  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PIN_MEM = (DEVICE == \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e8cae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hu_ju\\AppData\\Local\\Temp\\ipykernel_24032\\3129442314.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
      "C:\\Users\\hu_ju\\AppData\\Local\\Temp\\ipykernel_24032\\3129442314.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class order from ckpt: ['cel', 'cla', 'flu', 'gac', 'gel', 'org', 'pia', 'sax', 'tru', 'vio', 'voi']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "e:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\.cache\\mels\\irmas\\test\\(02) dont kill the whale-1__53f276b471__sr44100_dur3.0_m128_w30_h10_s0.npy",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# quick sanity checks\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_ds) > \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEmpty test dataset.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m x0, y0, clip0, p0 = \u001b[43mtest_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m x0.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x0.shape[\u001b[32m0\u001b[39m] == \u001b[32m2\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected mel shape (2, 128, T); got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(x0.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m y0.numel() == num_classes, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTarget length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my0.numel()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != num_classes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\src\\utils\\datasets.py:147\u001b[39m, in \u001b[36mIRMASTestWindowDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    145\u001b[39m mel_path = \u001b[38;5;28mself\u001b[39m.resolver.resolve(row[\u001b[33m\"\u001b[39m\u001b[33mfilepath\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mel_path.exists():\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(mel_path)\n\u001b[32m    149\u001b[39m mel = torch.from_numpy(\u001b[38;5;28mself\u001b[39m._load_mel(mel_path))  \u001b[38;5;66;03m# (C, F, T)\u001b[39;00m\n\u001b[32m    150\u001b[39m target = \u001b[38;5;28mself\u001b[39m._encode_multi_hot(row[\u001b[33m\"\u001b[39m\u001b[33mlabels_parsed\u001b[39m\u001b[33m\"\u001b[39m], index)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: e:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\.cache\\mels\\irmas\\test\\(02) dont kill the whale-1__53f276b471__sr44100_dur3.0_m128_w30_h10_s0.npy"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ----------------- HELPERS -----------------\n",
    "def load_model_state(ckpt_path: str) -> Dict[str, torch.Tensor]:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    sd = None\n",
    "    if isinstance(ckpt, dict):\n",
    "        for k in (\"model_state\", \"model_state_dict\", \"state_dict\", \"model\"):\n",
    "            if isinstance(ckpt.get(k), dict):\n",
    "                sd = ckpt[k]; break\n",
    "    if sd is None:\n",
    "        sd = ckpt if isinstance(ckpt, dict) else ckpt\n",
    "    # strip potential DDP prefix\n",
    "    return { (k[7:] if k.startswith(\"module.\") else k): v for k, v in sd.items() }\n",
    "\n",
    "def class_names_from_ckpt(ckpt_path: str, fallback: List[str]) -> Tuple[List[str], Dict[str,int]]:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    if isinstance(ckpt, dict) and isinstance(ckpt.get(\"label_to_idx\"), dict):\n",
    "        l2i = ckpt[\"label_to_idx\"]\n",
    "        ordered = [name for name, idx in sorted(l2i.items(), key=lambda kv: kv[1])]\n",
    "        return ordered, l2i\n",
    "    # Fallback only if absolutely necessary\n",
    "    return list(fallback), {n:i for i, n in enumerate(fallback)}\n",
    "\n",
    "# ----------------- CLASS ORDER (LOCK TO CKPT) -----------------\n",
    "train_order_names, label_to_idx = class_names_from_ckpt(RESUME_CKPT, IRMAS_CLASSES)\n",
    "num_classes = len(train_order_names)\n",
    "print(\"Class order from ckpt:\", train_order_names)\n",
    "\n",
    "# ----------------- MODEL -----------------\n",
    "model = CNNVarTime(in_ch=2, num_classes=num_classes, p_drop=0.5).to(DEVICE)\n",
    "state_dict = load_model_state(RESUME_CKPT)\n",
    "missing, unexpected = model.load_state_dict(state_dict, strict=True)\n",
    "assert not missing and not unexpected, f\"state_dict mismatch: missing={missing} unexpected={unexpected}\"\n",
    "model.eval()\n",
    "\n",
    "# ----------------- DATASET / LOADER -----------------\n",
    "# IMPORTANT: pass class_names=train_order_names so targets align with the checkpoint order\n",
    "test_ds = IRMASTestWindowDataset(\n",
    "    manifest_csv=Path(IRMAS_TEST_MANIFEST),\n",
    "    project_root=PROJECT_ROOT,\n",
    "    class_names=train_order_names,\n",
    "    per_example_norm=True,   # keep consistent with training\n",
    ")\n",
    "\n",
    "# quick sanity checks\n",
    "assert len(test_ds) > 0, \"Empty test dataset.\"\n",
    "x0, y0, clip0, p0 = test_ds[0]\n",
    "assert x0.ndim == 3 and x0.shape[0] == 2, f\"Expected mel shape (2, 128, T); got {tuple(x0.shape)}\"\n",
    "assert y0.numel() == num_classes, f\"Target length {y0.numel()} != num_classes {num_classes}\"\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=PIN_MEM\n",
    ")\n",
    "print(\"Test windows:\", len(test_ds))\n",
    "\n",
    "# ----------------- EVAL (clip-level by averaging logits) -----------------\n",
    "logits_by_clip = defaultdict(list)\n",
    "labels_by_clip = {}\n",
    "windows_per_clip = defaultdict(int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets, clip_ids, paths in test_loader:\n",
    "        inputs = inputs.to(DEVICE, non_blocking=PIN_MEM)\n",
    "        logits = model(inputs)                     # (B, C) raw logits (pre-softmax)\n",
    "        logits_cpu = logits.detach().cpu().numpy()\n",
    "        targets_np = targets.cpu().numpy()\n",
    "\n",
    "        for logit_vec, target_vec, clip_id in zip(logits_cpu, targets_np, clip_ids):\n",
    "            print(clip_id)\n",
    "            logits_by_clip[clip_id].append(logit_vec)               # accumulate windows\n",
    "            labels_by_clip[clip_id] = target_vec.astype(np.float32) # multi-hot GT per clip\n",
    "            windows_per_clip[clip_id] += 1\n",
    "\n",
    "rows = []\n",
    "for clip_id, logit_list in logits_by_clip.items():\n",
    "    stacked = np.stack(logit_list, 0)       # (W, C)\n",
    "    mean_logits = stacked.mean(axis=0)      # (C,)\n",
    "\n",
    "    # Single-class head (CE): convert to softmax probs for readability\n",
    "    exp = np.exp(mean_logits - mean_logits.max())\n",
    "    probs = exp / exp.sum()\n",
    "\n",
    "    pred_idx = int(mean_logits.argmax())\n",
    "    gt_vec = labels_by_clip[clip_id]        # multi-hot from manifest\n",
    "    hit1 = bool(gt_vec[pred_idx] > 0.5)\n",
    "\n",
    "    order = np.argsort(mean_logits)[::-1]\n",
    "    top3 = \", \".join(f\"{train_order_names[i]} ({probs[i]:.2f})\" for i in order[:3])\n",
    "    true_names = [train_order_names[i] for i, v in enumerate(gt_vec) if v > 0.5]\n",
    "\n",
    "    rows.append({\n",
    "        \"clip\": clip_id,\n",
    "        \"true_labels\": \"|\".join(true_names),\n",
    "        \"pred_label\": train_order_names[pred_idx],\n",
    "        \"pred_score\": float(probs[pred_idx]),\n",
    "        \"top3\": top3,\n",
    "        \"hit@1\": hit1,\n",
    "        # \"windows\": int(windows_per_clip[clip_id]),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values([\"hit@1\", \"pred_score\"], ascending=[True, False])\n",
    "print(\"Clip-level Top-1 accuracy:\", df[\"hit@1\"].mean())\n",
    "try:\n",
    "    display(df.head(10))\n",
    "except NameError:\n",
    "    print(df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349d6f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m per_class = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ci, cname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_order_names):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     mask = \u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtrue_labels\u001b[39m\u001b[33m\"\u001b[39m].str.contains(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(?:^|[|])\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(?:$|[|])\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     support = \u001b[38;5;28mint\u001b[39m(mask.sum())\n\u001b[32m      5\u001b[39m     correct = \u001b[38;5;28mint\u001b[39m((df.loc[mask, \u001b[33m\"\u001b[39m\u001b[33mpred_label\u001b[39m\u001b[33m\"\u001b[39m] == cname).sum())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "per_class = []\n",
    "for ci, cname in enumerate(train_order_names):\n",
    "    mask = df[\"true_labels\"].str.contains(rf\"(?:^|[|]){cname}(?:$|[|])\")\n",
    "    support = int(mask.sum())\n",
    "    correct = int((df.loc[mask, \"pred_label\"] == cname).sum())\n",
    "    per_class.append({\"class\": cname, \"support\": support, \"hit_rate\": (correct / support if support else float(\"nan\"))})\n",
    "per_class_df = pd.DataFrame(per_class).sort_values(\"hit_rate\", ascending=False)\n",
    "per_class_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
