{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TRAIN_MANIFEST = \"data/manifests/irmas_train_mels.csv\"\n",
    "\n",
    "EPOCHS       = 500\n",
    "BATCH_SIZE   = 32\n",
    "LR           = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "VAL_FRAC     = 0.15\n",
    "DROPOUT      = 0.3\n",
    "PATIENCE     = 100\n",
    "NUM_WORKERS  = 0 \n",
    "SEED = 1337\n",
    "\n",
    "RESUME = True # loads previous model weights, set to False if training from scratch\n",
    "TRAIN_NUMBER = \"train_6\" # directory to add  weights, change on each training run\n",
    "CKPT_DIR = Path(f\"saved_weights/irmas_pretrain_single_class/{TRAIN_NUMBER}\")\n",
    "RESUME_CKPT = (CKPT_DIR / \"last.pt\") if RESUME else None  # or CKPT_DIR/\"best_val_acc.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d2c1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006/500] train 1.5601/0.4738 | val 1.5740/0.4990 | time 5.8s\n",
      "  â†‘ new best val_acc: 0.4990\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SingleClassMelNpyDataset\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrain_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_loop\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m out = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_manifest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRAIN_MANIFEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCKPT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWEIGHT_DECAY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVAL_FRAC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDROPOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRESUME_CKPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_best_stamped\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m history = out[\u001b[33m\"\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\train_utils.py:289\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(train_manifest, ckpt_dir, epochs, batch_size, lr, weight_decay, val_frac, dropout, patience, num_workers, seed, resume_from, save_best_stamped)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m    287\u001b[39m     t0 = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     tr_loss, tr_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_mps_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_mem\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     va_loss, va_acc = evaluate(\n\u001b[32m    294\u001b[39m         model, val_loader, criterion, device, use_cuda_amp, use_mps_amp, pin_mem\n\u001b[32m    295\u001b[39m     )\n\u001b[32m    297\u001b[39m     scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\train_utils.py:134\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer, scaler, device, use_cuda_amp, use_mps_amp, pin_mem)\u001b[39m\n\u001b[32m    131\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m    132\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpin_mem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpin_mem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\src\\utils\\datasets.py:59\u001b[39m, in \u001b[36mSingleClassMelNpyDataset.__getitem__\u001b[39m\u001b[34m(self, i)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[32m     58\u001b[39m     row = \u001b[38;5;28mself\u001b[39m.df.iloc[i]\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     x = torch.from_numpy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_mel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfilepath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     60\u001b[39m     y = torch.tensor(\u001b[38;5;28mself\u001b[39m.label_to_idx[row[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]], dtype=torch.long)\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\src\\utils\\datasets.py:36\u001b[39m, in \u001b[36m_BaseMelDataset._load_mel\u001b[39m\u001b[34m(self, mel_path)\u001b[39m\n\u001b[32m     34\u001b[39m x = np.load(mel_path, allow_pickle=\u001b[38;5;28;01mFalse\u001b[39;00m).astype(np.float32)  \u001b[38;5;66;03m# (2, 128, T)\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.per_example_norm:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     x = \u001b[43mper_example_zscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\qingchaolaopian\\Instrument Sound\\Github\\ML-based-analysis-of-sound\\src\\utils\\datasets.py:15\u001b[39m, in \u001b[36mper_example_zscore\u001b[39m\u001b[34m(x, eps)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np.ndarray):\n\u001b[32m     14\u001b[39m     mean = x.mean(axis=(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m), keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     std  = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.clip(\u001b[38;5;28mmin\u001b[39m=eps)\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (x - mean) / std\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# torch.Tensor path\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:223\u001b[39m, in \u001b[36m_std\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_std\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, ddof=\u001b[32m0\u001b[39m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *,\n\u001b[32m    222\u001b[39m          where=\u001b[38;5;28;01mTrue\u001b[39;00m, mean=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     ret = \u001b[43m_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[43m=\u001b[49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m               \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu.ndarray):\n\u001b[32m    227\u001b[39m         ret = um.sqrt(ret, out=ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\_methods.py:205\u001b[39m, in \u001b[36m_var\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# Most general case; includes handling object arrays containing imaginary\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# numbers and complex types with non-native byteorder\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m     x = um.multiply(x, um.conjugate(x), out=x).real\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Compute degrees of freedom and make sure it is not negative.\u001b[39;00m\n\u001b[32m    208\u001b[39m rcount = um.maximum(rcount - ddof, \u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from src.utils.datasets import SingleClassMelNpyDataset\n",
    "from train_utils import train_loop\n",
    "out = train_loop(\n",
    "    train_manifest=TRAIN_MANIFEST,\n",
    "    ckpt_dir=CKPT_DIR,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    val_frac=VAL_FRAC,\n",
    "    dropout=DROPOUT,\n",
    "    patience=PATIENCE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    seed=SEED,\n",
    "    resume_from=RESUME_CKPT,\n",
    "    save_best_stamped=True,\n",
    ")\n",
    "history = out[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4879af03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CKPT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m CKPT = RESUME_CKPT = (\u001b[43mCKPT_DIR\u001b[49m / \u001b[33m\"\u001b[39m\u001b[33mlast.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# CKPT = 'saved_weights/irmas_pretrain_single_class/train_1/best_val_acc_junran_0.72.pt' # example of loading a different checkpoint\u001b[39;00m\n\u001b[32m      8\u001b[39m ckpt_loaded = torch.load(CKPT, map_location=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'CKPT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "CKPT = RESUME_CKPT = (CKPT_DIR / \"last.pt\")\n",
    "# CKPT = 'saved_weights/irmas_pretrain_single_class/train_1/best_val_acc_junran_0.72.pt' # example of loading a different checkpoint\n",
    "\n",
    "ckpt_loaded = torch.load(CKPT, map_location=\"cpu\")\n",
    "history = ckpt_loaded[\"history\"]\n",
    "print(list(history.keys()))  \n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss\"); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_acc\"], label=\"train\")\n",
    "plt.plot(history[\"val_acc\"], label=\"val\")\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy\"); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from src.models import CNNVarTime\n",
    "from train_utils import seed_everything, build_dataloaders\n",
    "\n",
    "# Ensure ckpt_loaded is available\n",
    "try:\n",
    "    ckpt_loaded\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Variable 'ckpt_loaded' is not defined. Please run the cell that loads the checkpoint (ckpt_loaded = torch.load(...)) before running this cell.\")\n",
    "\n",
    "label_to_idx = ckpt_loaded[\"label_to_idx\"]\n",
    "idx_to_label = [c for c, i in sorted(label_to_idx.items(), key=lambda kv: kv[1])]\n",
    "num_classes = len(idx_to_label)\n",
    "\n",
    "# rebuild val loader with same mapping (same split via same seed) \n",
    "_, val_loader, _ = build_dataloaders(\n",
    "    manifest_csv=TRAIN_MANIFEST,\n",
    "    val_frac=VAL_FRAC,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin_mem,\n",
    "    seed=SEED,\n",
    "    label_to_idx=label_to_idx,  \n",
    ")\n",
    "\n",
    "#  build model and load weights (strict) \n",
    "model = CNNVarTime(in_ch=2, num_classes=num_classes, p_drop=0.5).to(device)\n",
    "model.load_state_dict(ckpt_loaded[\"model_state\"], strict=True)\n",
    "model.eval()\n",
    "\n",
    "# predict validation set\n",
    "all_y_true, all_y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in val_loader:\n",
    "        X = X.to(device, non_blocking=pin_mem)\n",
    "        logits = model(X)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_y_pred.extend(preds)\n",
    "        all_y_true.extend(y.numpy())\n",
    "\n",
    "\n",
    "cm = confusion_matrix(all_y_true, all_y_pred, labels=list(range(num_classes)))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=idx_to_label)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp.plot(cmap=\"Blues\", ax=ax, colorbar=False, xticks_rotation=90)\n",
    "ax.set_title(\"Validation Confusion Matrix\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ---- classification report ----\n",
    "print(classification_report(all_y_true, all_y_pred, target_names=idx_to_label, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
